{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Лабораторная работа №6\n## Писарчук Надежда ИУ5-22М\n**Тема: Классификация текста.**\n\n**Задание:**\n\nДля произвольного набора данных, предназначенного для классификации текстов, решите задачу классификации текста двумя способами:\n\nСпособ 1. На основе CountVectorizer или TfidfVectorizer.\n\nСпособ 2. На основе моделей word2vec или Glove или fastText.\n\nСравните качество полученных моделей.\nДля поиска наборов данных в поисковой системе можно использовать ключевые слова \"datasets for text classification\".","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom typing import Dict, Tuple\nfrom scipy import stats\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score\nfrom sklearn.metrics import precision_score, recall_score, f1_score, classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.svm import SVC, NuSVC, LinearSVC, OneClassSVM, SVR, NuSVR, LinearSVR\nfrom sklearn.naive_bayes import ComplementNB\n\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom nltk.corpus import stopwords\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline \nsns.set(style=\"ticks\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\npd.set_option(\"display.max_columns\", None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-23T14:08:23.195548Z","iopub.execute_input":"2021-05-23T14:08:23.195883Z","iopub.status.idle":"2021-05-23T14:08:24.266935Z","shell.execute_reply.started":"2021-05-23T14:08:23.195854Z","shell.execute_reply":"2021-05-23T14:08:24.265549Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv\n/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"def accuracy_score_for_classes(\n    y_true: np.ndarray, \n    y_pred: np.ndarray) -> Dict[int, float]:\n    \"\"\"\n    Вычисление метрики accuracy для каждого класса\n    y_true - истинные значения классов\n    y_pred - предсказанные значения классов\n    Возвращает словарь: ключ - метка класса, \n    значение - Accuracy для данного класса\n    \"\"\"\n    # Для удобства фильтрации сформируем Pandas DataFrame \n    d = {'t': y_true, 'p': y_pred}\n    df = pd.DataFrame(data=d)\n    # Метки классов\n    classes = np.unique(y_true)\n    # Результирующий словарь\n    res = dict()\n    # Перебор меток классов\n    for c in classes:\n        # отфильтруем данные, которые соответствуют \n        # текущей метке класса в истинных значениях\n        temp_data_flt = df[df['t']==c]\n        # расчет accuracy для заданной метки класса\n        temp_acc = accuracy_score(\n            temp_data_flt['t'].values, \n            temp_data_flt['p'].values)\n        # сохранение результата в словарь\n        res[c] = temp_acc\n    return res\n\ndef print_accuracy_score_for_classes(\n    y_true: np.ndarray, \n    y_pred: np.ndarray):\n    \"\"\"\n    Вывод метрики accuracy для каждого класса\n    \"\"\"\n    accs = accuracy_score_for_classes(y_true, y_pred)\n    if len(accs)>0:\n        print('Метка \\t Accuracy')\n    for i in accs:\n        print('{} \\t {}'.format(i, accs[i]))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:24.268822Z","iopub.execute_input":"2021-05-23T14:08:24.269490Z","iopub.status.idle":"2021-05-23T14:08:24.278653Z","shell.execute_reply.started":"2021-05-23T14:08:24.269444Z","shell.execute_reply":"2021-05-23T14:08:24.277995Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv')\ntest = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:24.280414Z","iopub.execute_input":"2021-05-23T14:08:24.281021Z","iopub.status.idle":"2021-05-23T14:08:24.729571Z","shell.execute_reply.started":"2021-05-23T14:08:24.280978Z","shell.execute_reply":"2021-05-23T14:08:24.728833Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:24.730674Z","iopub.execute_input":"2021-05-23T14:08:24.731053Z","iopub.status.idle":"2021-05-23T14:08:24.736159Z","shell.execute_reply.started":"2021-05-23T14:08:24.731025Z","shell.execute_reply":"2021-05-23T14:08:24.734889Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(41157, 6)\n(3798, 6)\n","output_type":"stream"}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:24.737572Z","iopub.execute_input":"2021-05-23T14:08:24.737841Z","iopub.status.idle":"2021-05-23T14:08:24.768364Z","shell.execute_reply.started":"2021-05-23T14:08:24.737808Z","shell.execute_reply":"2021-05-23T14:08:24.767429Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   UserName  ScreenName   Location     TweetAt  \\\n0      3799       48751     London  16-03-2020   \n1      3800       48752         UK  16-03-2020   \n2      3801       48753  Vagabonds  16-03-2020   \n3      3802       48754        NaN  16-03-2020   \n4      3803       48755        NaN  16-03-2020   \n\n                                       OriginalTweet           Sentiment  \n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n1  advice Talk to your neighbours family to excha...            Positive  \n2  Coronavirus Australia: Woolworths to give elde...            Positive  \n3  My food stock is not the only one which is emp...            Positive  \n4  Me, ready to go at supermarket during the #COV...  Extremely Negative  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Extremely Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.Sentiment.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:24.777946Z","iopub.execute_input":"2021-05-23T14:08:24.778478Z","iopub.status.idle":"2021-05-23T14:08:24.799675Z","shell.execute_reply.started":"2021-05-23T14:08:24.778434Z","shell.execute_reply":"2021-05-23T14:08:24.798680Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Positive              11422\nNegative               9917\nNeutral                7713\nExtremely Positive     6624\nExtremely Negative     5481\nName: Sentiment, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train.Sentiment = train.Sentiment.replace({'Extremely Positive':'Positive','Extremely Negative':'Negative'})\ntest.Sentiment = test.Sentiment.replace({'Extremely Positive':'Positive','Extremely Negative':'Negative'})\n\nlenc = LabelEncoder()\ntest.Sentiment = lenc.fit_transform(test.Sentiment)\ntrain.Sentiment = lenc.fit_transform(train.Sentiment)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:24.939711Z","iopub.execute_input":"2021-05-23T14:08:24.940071Z","iopub.status.idle":"2021-05-23T14:08:24.977961Z","shell.execute_reply.started":"2021-05-23T14:08:24.940036Z","shell.execute_reply":"2021-05-23T14:08:24.977017Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:25.099944Z","iopub.execute_input":"2021-05-23T14:08:25.100278Z","iopub.status.idle":"2021-05-23T14:08:25.112448Z","shell.execute_reply.started":"2021-05-23T14:08:25.100248Z","shell.execute_reply":"2021-05-23T14:08:25.111370Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   UserName  ScreenName   Location     TweetAt  \\\n0      3799       48751     London  16-03-2020   \n1      3800       48752         UK  16-03-2020   \n2      3801       48753  Vagabonds  16-03-2020   \n3      3802       48754        NaN  16-03-2020   \n4      3803       48755        NaN  16-03-2020   \n\n                                       OriginalTweet  Sentiment  \n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...          1  \n1  advice Talk to your neighbours family to excha...          2  \n2  Coronavirus Australia: Woolworths to give elde...          2  \n3  My food stock is not the only one which is emp...          2  \n4  Me, ready to go at supermarket during the #COV...          0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x_train = train['OriginalTweet']\ny_train = train['Sentiment']\nx_test = test['OriginalTweet']\ny_test = test['Sentiment']","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:33:01.364229Z","iopub.execute_input":"2021-05-23T14:33:01.364791Z","iopub.status.idle":"2021-05-23T14:33:01.371107Z","shell.execute_reply.started":"2021-05-23T14:33:01.364752Z","shell.execute_reply":"2021-05-23T14:33:01.370342Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"##  Очистка данных","metadata":{}},{"cell_type":"code","source":"import re\ndef preprocess_sentence(w):\n    # отделение слов и знаков пунктуации пробелом\n    # eg: \"he is a boy.\" => \"he is a boy .\"\n    w = w.lower()\n    w = re.sub('\\t\\n', '', w)\n    w = re.sub(r'http\\S+', '', w)\n    w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n    w = re.sub(r'[\" \"]+', \" \", w)\n    \n    # удаляем все кроме (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n    w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,`']+\", \" \", w)\n\n    w = w.strip()\n    tokens = w.split(' ')\n\n    stop_words = set(stopwords.words('english')) # remove stopwords\n    tokens = [word for word in tokens if not word in stop_words]\n    tokens = ' '.join(tokens)\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:33:02.767169Z","iopub.execute_input":"2021-05-23T14:33:02.767663Z","iopub.status.idle":"2021-05-23T14:33:02.774782Z","shell.execute_reply.started":"2021-05-23T14:33:02.767629Z","shell.execute_reply":"2021-05-23T14:33:02.773802Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"x_train = x_train.apply(preprocess_sentence)\nx_test = x_test.apply(preprocess_sentence)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:33:04.964354Z","iopub.execute_input":"2021-05-23T14:33:04.964702Z","iopub.status.idle":"2021-05-23T14:33:14.328829Z","shell.execute_reply.started":"2021-05-23T14:33:04.964670Z","shell.execute_reply":"2021-05-23T14:33:14.327699Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Сформируем общий словарь для обучения моделей из обучающей и тестовой выборки\nvocab_list = x_train.tolist() + x_test.tolist()\nprint(len(vocab_list))\nvocab_list[1:10]","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-05-23T14:33:14.330176Z","iopub.execute_input":"2021-05-23T14:33:14.330491Z","iopub.status.idle":"2021-05-23T14:33:14.341199Z","shell.execute_reply.started":"2021-05-23T14:33:14.330460Z","shell.execute_reply":"2021-05-23T14:33:14.340230Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"44955\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"['advice talk neighbours family exchange phone numbers create contact list phone numbers neighbours schools employer chemist gp set online shopping accounts poss adequate supplies regular meds order',\n 'coronavirus australia woolworths give elderly , disabled dedicated shopping hours amid covid outbreak',\n 'food stock one empty . . . please , panic , enough food everyone take need . stay calm , stay safe . covid france covid covid coronavirus confinement confinementotal confinementgeneral',\n \", ready go supermarket covid outbreak . i'm paranoid , food stock litteraly empty . coronavirus serious thing , please , panic . causes shortage . . . coronavirusfrance restezchezvous stayathome confinement\",\n 'news region first confirmed covid case came sullivan county last week , people flocked area stores purchase cleaning supplies , hand sanitizer , food , toilet paper goods , tim dodson reports',\n \"cashier grocery store sharing insights covid prove credibility commented i'm civics class know i'm talking .\",\n 'supermarket today . buy toilet paper . rebel toiletpapercrisis covid',\n 'due covid retail store classroom atlanta open walk business classes next two weeks , beginning monday , march . continue process online phone orders normal ! thank understanding !',\n 'corona prevention , stop buy things cash use online payment methods corona spread notes . also prefer online shopping home . time fight covid ? . govindia indiafightscorona']"},"metadata":{}}]},{"cell_type":"code","source":"train['OriginalTweet'][0:10][4]","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:35.518700Z","iopub.execute_input":"2021-05-23T14:08:35.518986Z","iopub.status.idle":"2021-05-23T14:08:35.530546Z","shell.execute_reply.started":"2021-05-23T14:08:35.518958Z","shell.execute_reply":"2021-05-23T14:08:35.529654Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"\"Me, ready to go at supermarket during the #COVID19 outbreak.\\r\\r\\n\\r\\r\\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\\r\\r\\n\\r\\r\\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\""},"metadata":{}}]},{"cell_type":"code","source":"vocabVect = CountVectorizer()\nvocabVect.fit(vocab_list)\ncorpusVocab = vocabVect.vocabulary_\nprint('Количество сформированных признаков - {}'.format(len(corpusVocab)))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:35.532092Z","iopub.execute_input":"2021-05-23T14:08:35.532417Z","iopub.status.idle":"2021-05-23T14:08:36.867236Z","shell.execute_reply.started":"2021-05-23T14:08:35.532360Z","shell.execute_reply":"2021-05-23T14:08:36.866175Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Количество сформированных признаков - 54546\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in list(corpusVocab)[1:10]:\n    print('{}={}'.format(i, corpusVocab[i]))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:36.868319Z","iopub.execute_input":"2021-05-23T14:08:36.868626Z","iopub.status.idle":"2021-05-23T14:08:36.878844Z","shell.execute_reply.started":"2021-05-23T14:08:36.868597Z","shell.execute_reply":"2021-05-23T14:08:36.877906Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"phil=36274\ngahan=18888\nchrisitv=8219\nadvice=670\ntalk=47397\nneighbours=32568\nfamily=16737\nexchange=16272\nphone=36318\n","output_type":"stream"}]},{"cell_type":"code","source":"tfidfv = TfidfVectorizer(ngram_range=(1,3))\ntfidf_ngram_features = tfidfv.fit_transform(vocab_list)\ntfidf_ngram_features","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:36.880349Z","iopub.execute_input":"2021-05-23T14:08:36.880651Z","iopub.status.idle":"2021-05-23T14:08:45.259516Z","shell.execute_reply.started":"2021-05-23T14:08:36.880623Z","shell.execute_reply":"2021-05-23T14:08:45.258663Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<44955x1141506 sparse matrix of type '<class 'numpy.float64'>'\n\twith 2263622 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def VectorizeAndClassify(vectorizers_list, classifiers_list):\n    for v in vectorizers_list:\n        for c in classifiers_list:\n            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n            score = cross_val_score(pipeline1, x_train[:10000], y_train[:10000], scoring='accuracy', cv=3,).mean()\n            print('Векторизация - {}'.format(v))\n            print('Модель для классификации - {}'.format(c))\n            print('Accuracy = {}'.format(score))\n            print('===========================')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:45.260689Z","iopub.execute_input":"2021-05-23T14:08:45.260960Z","iopub.status.idle":"2021-05-23T14:08:45.269149Z","shell.execute_reply.started":"2021-05-23T14:08:45.260934Z","shell.execute_reply":"2021-05-23T14:08:45.268432Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\nclassifiers_list = [RandomForestClassifier(), ComplementNB(), LogisticRegression(C=3.0, solver='lbfgs', max_iter=1000), LinearSVC()]\nVectorizeAndClassify(vectorizers_list, classifiers_list)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:08:45.272262Z","iopub.execute_input":"2021-05-23T14:08:45.272661Z","iopub.status.idle":"2021-05-23T14:12:22.159946Z","shell.execute_reply.started":"2021-05-23T14:08:45.272630Z","shell.execute_reply":"2021-05-23T14:12:22.158936Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Векторизация - CountVectorizer(vocabulary={'aa': 0, 'aaa': 1, 'aaaaakubosan': 2, 'aaaaas': 3,\n                            'aaaand': 4, 'aaachatterjee': 5, 'aaanews': 6,\n                            'aaannnddd': 7, 'aaanortheast': 8, 'aabutan': 9,\n                            'aacopd': 10, 'aacounty': 11, 'aacountygovt': 12,\n                            'aadeshrawal': 13, 'aadya': 14, 'aadyasitara': 15,\n                            'aafp': 16, 'aahealth': 17, 'aahh': 18, 'aai': 19,\n                            'aaisp': 20, 'aajeevika': 21, 'aajtak': 22,\n                            'aakash': 23, 'aalonzowatt': 24, 'aalto': 25,\n                            'aaltouniversity': 26, 'aalwajih': 27,\n                            'aamaadmi': 28, 'aamaadmiparty': 29, ...})\nМодель для классификации - RandomForestClassifier()\nAccuracy = 0.6917000938246195\n===========================\nВекторизация - CountVectorizer(vocabulary={'aa': 0, 'aaa': 1, 'aaaaakubosan': 2, 'aaaaas': 3,\n                            'aaaand': 4, 'aaachatterjee': 5, 'aaanews': 6,\n                            'aaannnddd': 7, 'aaanortheast': 8, 'aabutan': 9,\n                            'aacopd': 10, 'aacounty': 11, 'aacountygovt': 12,\n                            'aadeshrawal': 13, 'aadya': 14, 'aadyasitara': 15,\n                            'aafp': 16, 'aahealth': 17, 'aahh': 18, 'aai': 19,\n                            'aaisp': 20, 'aajeevika': 21, 'aajtak': 22,\n                            'aakash': 23, 'aalonzowatt': 24, 'aalto': 25,\n                            'aaltouniversity': 26, 'aalwajih': 27,\n                            'aamaadmi': 28, 'aamaadmiparty': 29, ...})\nМодель для классификации - ComplementNB()\nAccuracy = 0.6462999629297063\n===========================\nВекторизация - CountVectorizer(vocabulary={'aa': 0, 'aaa': 1, 'aaaaakubosan': 2, 'aaaaas': 3,\n                            'aaaand': 4, 'aaachatterjee': 5, 'aaanews': 6,\n                            'aaannnddd': 7, 'aaanortheast': 8, 'aabutan': 9,\n                            'aacopd': 10, 'aacounty': 11, 'aacountygovt': 12,\n                            'aadeshrawal': 13, 'aadya': 14, 'aadyasitara': 15,\n                            'aafp': 16, 'aahealth': 17, 'aahh': 18, 'aai': 19,\n                            'aaisp': 20, 'aajeevika': 21, 'aajtak': 22,\n                            'aakash': 23, 'aalonzowatt': 24, 'aalto': 25,\n                            'aaltouniversity': 26, 'aalwajih': 27,\n                            'aamaadmi': 28, 'aamaadmiparty': 29, ...})\nМодель для классификации - LogisticRegression(C=3.0, max_iter=1000)\nAccuracy = 0.7155993643755497\n===========================\nВекторизация - CountVectorizer(vocabulary={'aa': 0, 'aaa': 1, 'aaaaakubosan': 2, 'aaaaas': 3,\n                            'aaaand': 4, 'aaachatterjee': 5, 'aaanews': 6,\n                            'aaannnddd': 7, 'aaanortheast': 8, 'aabutan': 9,\n                            'aacopd': 10, 'aacounty': 11, 'aacountygovt': 12,\n                            'aadeshrawal': 13, 'aadya': 14, 'aadyasitara': 15,\n                            'aafp': 16, 'aahealth': 17, 'aahh': 18, 'aai': 19,\n                            'aaisp': 20, 'aajeevika': 21, 'aajtak': 22,\n                            'aakash': 23, 'aalonzowatt': 24, 'aalto': 25,\n                            'aaltouniversity': 26, 'aalwajih': 27,\n                            'aamaadmi': 28, 'aamaadmiparty': 29, ...})\nМодель для классификации - LinearSVC()\nAccuracy = 0.7094994142485634\n===========================\nВекторизация - TfidfVectorizer(vocabulary={'aa': 0, 'aaa': 1, 'aaaaakubosan': 2, 'aaaaas': 3,\n                            'aaaand': 4, 'aaachatterjee': 5, 'aaanews': 6,\n                            'aaannnddd': 7, 'aaanortheast': 8, 'aabutan': 9,\n                            'aacopd': 10, 'aacounty': 11, 'aacountygovt': 12,\n                            'aadeshrawal': 13, 'aadya': 14, 'aadyasitara': 15,\n                            'aafp': 16, 'aahealth': 17, 'aahh': 18, 'aai': 19,\n                            'aaisp': 20, 'aajeevika': 21, 'aajtak': 22,\n                            'aakash': 23, 'aalonzowatt': 24, 'aalto': 25,\n                            'aaltouniversity': 26, 'aalwajih': 27,\n                            'aamaadmi': 28, 'aamaadmiparty': 29, ...})\nМодель для классификации - RandomForestClassifier()\nAccuracy = 0.6763995835696347\n===========================\nВекторизация - TfidfVectorizer(vocabulary={'aa': 0, 'aaa': 1, 'aaaaakubosan': 2, 'aaaaas': 3,\n                            'aaaand': 4, 'aaachatterjee': 5, 'aaanews': 6,\n                            'aaannnddd': 7, 'aaanortheast': 8, 'aabutan': 9,\n                            'aacopd': 10, 'aacounty': 11, 'aacountygovt': 12,\n                            'aadeshrawal': 13, 'aadya': 14, 'aadyasitara': 15,\n                            'aafp': 16, 'aahealth': 17, 'aahh': 18, 'aai': 19,\n                            'aaisp': 20, 'aajeevika': 21, 'aajtak': 22,\n                            'aakash': 23, 'aalonzowatt': 24, 'aalto': 25,\n                            'aaltouniversity': 26, 'aalwajih': 27,\n                            'aamaadmi': 28, 'aamaadmiparty': 29, ...})\nМодель для классификации - ComplementNB()\nAccuracy = 0.6464996829616975\n===========================\nВекторизация - TfidfVectorizer(vocabulary={'aa': 0, 'aaa': 1, 'aaaaakubosan': 2, 'aaaaas': 3,\n                            'aaaand': 4, 'aaachatterjee': 5, 'aaanews': 6,\n                            'aaannnddd': 7, 'aaanortheast': 8, 'aabutan': 9,\n                            'aacopd': 10, 'aacounty': 11, 'aacountygovt': 12,\n                            'aadeshrawal': 13, 'aadya': 14, 'aadyasitara': 15,\n                            'aafp': 16, 'aahealth': 17, 'aahh': 18, 'aai': 19,\n                            'aaisp': 20, 'aajeevika': 21, 'aajtak': 22,\n                            'aakash': 23, 'aalonzowatt': 24, 'aalto': 25,\n                            'aaltouniversity': 26, 'aalwajih': 27,\n                            'aamaadmi': 28, 'aamaadmiparty': 29, ...})\nМодель для классификации - LogisticRegression(C=3.0, max_iter=1000)\nAccuracy = 0.7047998441115858\n===========================\nВекторизация - TfidfVectorizer(vocabulary={'aa': 0, 'aaa': 1, 'aaaaakubosan': 2, 'aaaaas': 3,\n                            'aaaand': 4, 'aaachatterjee': 5, 'aaanews': 6,\n                            'aaannnddd': 7, 'aaanortheast': 8, 'aabutan': 9,\n                            'aacopd': 10, 'aacounty': 11, 'aacountygovt': 12,\n                            'aadeshrawal': 13, 'aadya': 14, 'aadyasitara': 15,\n                            'aafp': 16, 'aahealth': 17, 'aahh': 18, 'aai': 19,\n                            'aaisp': 20, 'aajeevika': 21, 'aajtak': 22,\n                            'aakash': 23, 'aalonzowatt': 24, 'aalto': 25,\n                            'aaltouniversity': 26, 'aalwajih': 27,\n                            'aamaadmi': 28, 'aamaadmiparty': 29, ...})\nМодель для классификации - LinearSVC()\nAccuracy = 0.7113996042675653\n===========================\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Лучший результат покаазала модель LogisticRegression(C=3.0, max_iter=1000) с CountVectorizer\n### word2vec","metadata":{}},{"cell_type":"code","source":"import gensim\nfrom gensim.models import word2vec","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:12:22.161619Z","iopub.execute_input":"2021-05-23T14:12:22.162022Z","iopub.status.idle":"2021-05-23T14:12:22.166058Z","shell.execute_reply.started":"2021-05-23T14:12:22.161980Z","shell.execute_reply":"2021-05-23T14:12:22.165345Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from nltk import WordPunctTokenizer\nfrom nltk.corpus import stopwords\n# Подготовим корпус\ncorpus = []\nstop_words = stopwords.words('english')\ntok = WordPunctTokenizer()\nfor line in vocab_list:\n    line1 = line.strip().lower()\n    line1 = re.sub(\"[^a-zA-Z]\",\" \", line1)\n    text_tok = tok.tokenize(line1)\n    text_tok1 = [w for w in text_tok if not w in stop_words]\n    corpus.append(text_tok1)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:14:11.508070Z","iopub.execute_input":"2021-05-23T14:14:11.508731Z","iopub.status.idle":"2021-05-23T14:14:14.299401Z","shell.execute_reply.started":"2021-05-23T14:14:11.508695Z","shell.execute_reply":"2021-05-23T14:14:14.298595Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"corpus[1]","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:14:49.293187Z","iopub.execute_input":"2021-05-23T14:14:49.293548Z","iopub.status.idle":"2021-05-23T14:14:49.299560Z","shell.execute_reply.started":"2021-05-23T14:14:49.293504Z","shell.execute_reply":"2021-05-23T14:14:49.298637Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"['advice',\n 'talk',\n 'neighbours',\n 'family',\n 'exchange',\n 'phone',\n 'numbers',\n 'create',\n 'contact',\n 'list',\n 'phone',\n 'numbers',\n 'neighbours',\n 'schools',\n 'employer',\n 'chemist',\n 'gp',\n 'set',\n 'online',\n 'shopping',\n 'accounts',\n 'poss',\n 'adequate',\n 'supplies',\n 'regular',\n 'meds',\n 'order']"},"metadata":{}}]},{"cell_type":"code","source":"%time model = word2vec.Word2Vec(corpus, workers=4, min_count=10, window=10, sample=1e-3)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:16:07.132214Z","iopub.execute_input":"2021-05-23T14:16:07.132569Z","iopub.status.idle":"2021-05-23T14:16:11.151571Z","shell.execute_reply.started":"2021-05-23T14:16:07.132538Z","shell.execute_reply":"2021-05-23T14:16:11.150549Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"CPU times: user 11.6 s, sys: 71.3 ms, total: 11.7 s\nWall time: 4.01 s\n","output_type":"stream"}]},{"cell_type":"code","source":"# Проверим, что модель обучилась\nprint(model.wv.most_similar(positive=['find'], topn=5))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:16:25.228273Z","iopub.execute_input":"2021-05-23T14:16:25.228645Z","iopub.status.idle":"2021-05-23T14:16:25.241617Z","shell.execute_reply.started":"2021-05-23T14:16:25.228612Z","shell.execute_reply":"2021-05-23T14:16:25.240687Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"[('try', 0.779373049736023), ('looking', 0.7359310388565063), ('gift', 0.7253180742263794), ('delivered', 0.7166185975074768), ('meal', 0.7112691402435303)]\n","output_type":"stream"}]},{"cell_type":"code","source":"vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\nclassifiers_list = [RandomForestClassifier(), ComplementNB(), LogisticRegression(C=3.0, solver='lbfgs', max_iter=1000), LinearSVC()]\nVectorizeAndClassify(vectorizers_list, classifiers_list)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(corpus)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:24:57.545442Z","iopub.execute_input":"2021-05-23T14:24:57.545786Z","iopub.status.idle":"2021-05-23T14:24:57.551745Z","shell.execute_reply.started":"2021-05-23T14:24:57.545754Z","shell.execute_reply":"2021-05-23T14:24:57.550706Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"44955"},"metadata":{}}]},{"cell_type":"code","source":"x_train.value.values[0]","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:35:46.475112Z","iopub.execute_input":"2021-05-23T14:35:46.475627Z","iopub.status.idle":"2021-05-23T14:35:46.525360Z","shell.execute_reply.started":"2021-05-23T14:35:46.475575Z","shell.execute_reply":"2021-05-23T14:35:46.523697Z"},"trusted":true},"execution_count":55,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-bc32498b17da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'value'"],"ename":"AttributeError","evalue":"'Series' object has no attribute 'value'","output_type":"error"}]},{"cell_type":"code","source":"boundary = 30000\nX_train = corpus[:boundary] \nX_test = corpus[boundary:boundary+1000]\nY_train = y_train[:boundary]\nY_test = y_train[boundary:boundary+1000]\n\ndef sentiment(v, c):\n    for v in vectorizers_list:\n        for c in classifiers_list:\n            model = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n            model.fit(X_train, Y_train)\n            y_pred = model.predict(X_test)\n            \n            print('Модель для классификации - {}'.format(c))\n            \n            print_accuracy_score_for_classes(Y_test, y_pred)\n\n            print('===========================')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:44:27.681272Z","iopub.execute_input":"2021-05-23T14:44:27.681635Z","iopub.status.idle":"2021-05-23T14:44:27.693216Z","shell.execute_reply.started":"2021-05-23T14:44:27.681604Z","shell.execute_reply":"2021-05-23T14:44:27.692349Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"class EmbeddingVectorizer(object):\n    '''\n    Для текста усредним вектора входящих в него слов\n    '''\n    def __init__(self, model):\n        self.model = model\n        self.size = model.vector_size\n\n    def fit(self, X, y):\n        return self\n\n    def transform(self, X):\n        return np.array([np.mean(\n            [self.model[w] for w in words if w in self.model] \n            or [np.zeros(self.size)], axis=0)\n            for words in X])","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:23:47.094922Z","iopub.execute_input":"2021-05-23T14:23:47.095240Z","iopub.status.idle":"2021-05-23T14:23:47.102548Z","shell.execute_reply.started":"2021-05-23T14:23:47.095212Z","shell.execute_reply":"2021-05-23T14:23:47.101474Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"vectorizers_list = [EmbeddingVectorizer(model.wv)]\nclassifiers_list = [RandomForestClassifier(),  LogisticRegression(C=3.0, solver='lbfgs', max_iter=1000), LinearSVC()]\nsentiment(vectorizers_list, classifiers_list)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:44:31.111992Z","iopub.execute_input":"2021-05-23T14:44:31.112348Z","iopub.status.idle":"2021-05-23T14:46:28.611662Z","shell.execute_reply.started":"2021-05-23T14:44:31.112313Z","shell.execute_reply":"2021-05-23T14:46:28.610610Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Модель для классификации - RandomForestClassifier()\nМетка \t Accuracy\n0 \t 0.6203208556149733\n1 \t 0.3285024154589372\n2 \t 0.6610978520286396\n===========================\nМодель для классификации - LogisticRegression(C=3.0, max_iter=1000)\nМетка \t Accuracy\n0 \t 0.6283422459893048\n1 \t 0.34782608695652173\n2 \t 0.7303102625298329\n===========================\nМодель для классификации - LinearSVC()\nМетка \t Accuracy\n0 \t 0.6310160427807486\n1 \t 0.3140096618357488\n2 \t 0.7446300715990454\n===========================\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}